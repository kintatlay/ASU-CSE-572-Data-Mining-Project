{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kinlay/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/kinlay/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Extract data from CSVs\n",
    "cgmData_file_1 = pd.read_csv('CGMData.csv', sep=',', low_memory = False)\n",
    "cgmData_file_2 = pd.read_csv('CGM_patient2.csv', sep=',', low_memory = False)\n",
    "cgm = pd.concat([cgmData_file_1, cgmData_file_2],axis=0)\n",
    "# cgm = pd.read_csv('CGMData.csv', sep=',', low_memory = False)\n",
    "cgm['dateTime'] = pd.to_datetime(cgm['Date'] + ' ' + cgm['Time'])\n",
    "cgm = cgm.sort_values(by='dateTime',ascending=True)\n",
    "# display(cgm)\n",
    "\n",
    "insulinData_file_1 = pd.read_csv('InsulinData.csv', sep=',', low_memory = False)\n",
    "insulinData_file_2 = pd.read_csv('Insulin_patient2.csv', sep=',', low_memory = False)\n",
    "insulin = pd.concat([insulinData_file_1, insulinData_file_2],axis=0)\n",
    "# insulin = pd.read_csv('InsulinData.csv', sep=',', low_memory = False)\n",
    "insulin['dateTime'] = pd.to_datetime(insulin['Date'] + ' ' + insulin['Time'])\n",
    "insulin = insulin.sort_values(by='dateTime',ascending=True)\n",
    "# display(insulin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for meal time\n",
    "# Compare the dateTime to identify how long have one eaten the previous meal\n",
    "mealTimes = insulin.loc[insulin['BWZ Carb Input (grams)'] > 0][['Index', 'Date', 'Time', 'BWZ Carb Input (grams)', 'dateTime']]\n",
    "mealTimes['diff'] = mealTimes['dateTime'].diff(periods=1)\n",
    "mealTimes['shiftUp'] = mealTimes['diff'].shift(-1)\n",
    "# display(mealTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the previous meal time, filter out any meals eaten before the threshold (2 hours)\n",
    "mealTimes = mealTimes.loc[(mealTimes['shiftUp'] > datetime.timedelta (minutes = 120)) | (pd.isnull(mealTimes['shiftUp']))]\n",
    "# display(mealTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>304.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>212.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>736</td>\n",
       "      <td>146.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>737</td>\n",
       "      <td>201.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>738</td>\n",
       "      <td>159.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>739</td>\n",
       "      <td>172.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>143.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>741 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4      5      6      7      8      9   \\\n",
       "0    314.0  310.0  309.0  311.0  311.0  311.0  312.0    NaN    NaN    NaN   \n",
       "1     58.0   59.0   63.0   71.0   81.0  102.0  131.0  140.0  147.0  153.0   \n",
       "2    304.0  292.0  281.0  268.0  259.0  255.0  248.0  241.0  231.0  220.0   \n",
       "3     40.0   40.0   40.0   40.0   60.0   71.0   83.0   87.0  100.0  112.0   \n",
       "4    212.0  210.0  204.0  200.0  199.0  201.0  201.0  194.0  188.0  183.0   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "736  146.0  143.0  140.0  135.0  123.0  113.0  109.0  102.0  103.0  117.0   \n",
       "737  201.0  198.0  198.0  200.0  199.0  200.0  197.0  187.0  175.0  172.0   \n",
       "738  159.0  158.0  152.0  153.0  152.0  150.0  147.0  143.0  134.0  132.0   \n",
       "739  172.0  179.0  186.0  207.0  210.0  216.0  222.0  233.0  248.0  254.0   \n",
       "740  143.0  145.0  146.0  147.0  146.0  147.0  160.0  169.0  169.0  165.0   \n",
       "\n",
       "     ...  55  56  57  58  59  60  61  62  63  64  \n",
       "0    ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "1    ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "2    ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "3    ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "4    ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "..   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  \n",
       "736  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "737  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "738  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "739  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "740  ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "\n",
       "[741 rows x 65 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe. Using the meal time data from insulindata file and filter out the relevant time. Add those rows into the new dataframe\n",
    "cgmdata_withMeal = pd.DataFrame()\n",
    "for i in range(len(mealTimes)) : \n",
    "    preMealTime = mealTimes['dateTime'].iloc[i] - datetime.timedelta(minutes = 30)\n",
    "    endMealTime = mealTimes['dateTime'].iloc[i] + datetime.timedelta(minutes = 120)\n",
    "    filteredcgmdata = cgm.loc[(cgm['dateTime'] >= preMealTime) & (cgm['dateTime'] < endMealTime )]\n",
    "#     display(filteredcgmdata)\n",
    "    arr = []\n",
    "    for j in range(len(filteredcgmdata)) :\n",
    "        arr.append(filteredcgmdata['Sensor Glucose (mg/dL)'].iloc[j])\n",
    "    cgmdata_withMeal = cgmdata_withMeal.append(pd.Series(arr), ignore_index=True)\n",
    "\n",
    "# cgmdata_withMeal = cgmdata_withMeal.dropna()\n",
    "cgmdata_withMeal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply interpolation for missing data\n",
    "no_of_rows= cgmdata_withMeal.shape[0]\n",
    "no_of_columns = cgmdata_withMeal.shape[1]\n",
    "cgmdata_withMeal.dropna(axis=0, how='all', thresh=no_of_columns/4, subset=None, inplace=True)\n",
    "cgmdata_withMeal.dropna(axis=1, how='all', thresh=no_of_rows/4, subset=None, inplace=True)\n",
    "cgmdata_withMeal.interpolate(axis=0, method ='linear', limit_direction ='forward', inplace=True)\n",
    "cgmdata_withMeal.bfill(axis=1,inplace=True)\n",
    "cgmdata_withMeal['label'] = 1\n",
    "# display(cgmdata_withMeal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the no meal start time into an array\n",
    "no_meal_time = []\n",
    "for i in range(len(mealTimes)) : \n",
    "    startTime = mealTimes['dateTime'].iloc[i] + datetime.timedelta(minutes = 120)\n",
    "    endTime = startTime + datetime.timedelta(minutes = 120)\n",
    "    fullDataEndTime = insulin['dateTime'].iloc[-1]\n",
    "    no_meal_continue = True\n",
    "    while (no_meal_continue == True) :\n",
    "        tempRange = insulin.loc[(insulin['dateTime'] >= startTime) & (insulin['dateTime'] < endTime) & (insulin['BWZ Carb Input (grams)'] > 0)]\n",
    "        if (len(tempRange) > 0) :\n",
    "            no_meal_continue = False\n",
    "        else :\n",
    "            no_meal_time.append(startTime)\n",
    "        startTime = startTime + datetime.timedelta(minutes = 120)\n",
    "        endTime = endTime + datetime.timedelta(minutes = 120)\n",
    "        if (startTime > fullDataEndTime) :\n",
    "            no_meal_continue = False\n",
    "# display(no_meal_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the no meal start time and apply to the cgmdata file\n",
    "cgmdata_noMeal = pd.DataFrame()\n",
    "for i in no_meal_time:\n",
    "    noMealStartTime = i\n",
    "    noMealEndTime = i + datetime.timedelta(minutes = 120)\n",
    "    filteredcgmdata = cgm.loc[(cgm['dateTime'] >= noMealStartTime) & (cgm['dateTime'] < noMealEndTime)]\n",
    "    arr = []\n",
    "    for j in range(len(filteredcgmdata)):\n",
    "        arr.append(filteredcgmdata['Sensor Glucose (mg/dL)'].iloc[j])\n",
    "    if (len(arr) > 24):\n",
    "        continue\n",
    "    cgmdata_noMeal = cgmdata_noMeal.append(pd.Series(arr), ignore_index=True)\n",
    "    \n",
    "# cgmdata_noMeal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_rows= cgmdata_noMeal.shape[0]\n",
    "no_of_columns = cgmdata_noMeal.shape[1]\n",
    "cgmdata_noMeal.dropna(axis=0, how='all', thresh=no_of_columns/4, subset=None, inplace=True)\n",
    "cgmdata_noMeal.dropna(axis=1, how='all', thresh=no_of_rows/4, subset=None, inplace=True)\n",
    "cgmdata_noMeal.interpolate(axis=0, method ='linear', limit_direction ='forward', inplace=True)\n",
    "cgmdata_noMeal.bfill(axis=1,inplace=True)\n",
    "cgmdata_noMeal['label'] = 0\n",
    "# display(cgmdata_noMeal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalResult = pd.concat([cgmdata_withMeal, cgmdata_noMeal], sort = False)\n",
    "totalResult = totalResult.interpolate(axis = 0)\n",
    "# display(totalResult)\n",
    "condense_totalResult = totalResult[totalResult.columns[:24]]\n",
    "# display(totalResult)\n",
    "# display(condense_totalResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into train and test\n",
    "x = np.asarray(condense_totalResult)\n",
    "y = np.asarray(totalResult['label'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, random_state=1)\n",
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# result = loaded_model.score(x_test, y_test)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reference: https://towardsdatascience.com/a-quick-overview-of-5-scikit-learn-classification-algorithms-33fdc11ab0b9\n",
    "# # Logistic regression - train the model and then predict() function to make predictions on the test set\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# clf = LogisticRegression().fit(x_train, y_train)\n",
    "# predictions_logistic = clf.predict(x_test)\n",
    "\n",
    "# # Run classification report to compare predictions (we care about the accuracy f1-score)\n",
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(y_test, predictions_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # KNN - try KNN and run classification report to compare prediction (we care about the accuracy f1-score)\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# neigh = KNeighborsClassifier()\n",
    "# neigh.fit(x_train, y_train)\n",
    "# predictions = neigh.predict(x_test)\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Decision Tree - run classification report to compare prediction \n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# clf = DecisionTreeClassifier(random_state=0)\n",
    "# clf.fit(x_train, y_train)\n",
    "# predictions = clf.predict(x_test)\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Random Forrest - run classification report to compare prediction \n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# clf = RandomForestClassifier(random_state=0)\n",
    "# clf.fit(x_train, y_train)\n",
    "# predictions = clf.predict(x_test)\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gradient boosting - run classification report to compare prediction \n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# clf_win = GradientBoostingClassifier(random_state=0)\n",
    "# clf_win.fit(x_train, y_train)\n",
    "# predictions = clf_win.predict(x_test)\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'finalized_model.sav'\n",
    "# pickle.dump(clf_win, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
